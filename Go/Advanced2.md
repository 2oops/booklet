# Advanced2

***

**Golang并发**

1. Go 语言通过编译器运行时（runtime），从语言上支持了并发的特性，由goroutine特性完成，**goroutine由语言运行时调度完成，而线程是由操作系统调度完成**，此外，Go 语言还提供 **channel** 在多个 goroutine 间进行通信。goroutine和channel是golang秉承并发模式的重要实现基础。

2. go从语言层面就支持并发，同时实现了自动垃圾回收机制

   进程和线程：

   进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位

   线程是进程的一个执行实体，是CPU调度和分派的基本单位

   并发和并行：

   多线程在单核CPU上运行，称为并发（主要通过切换时间片来实现“同时”运行）

   多线程程序在多核CPU上运行，称为并行

   协程和线程：

   协程：独立的栈空间，共享堆空间，调度由用户自己控制

   线程：一个线程上可以跑多个协程，协程是轻量级的线程

   **goroutine:**

   说到底就是线程，但是比线程小，十几个 goroutine 可能体现在底层就是五六个线程，而且Go语言内部也实现了 goroutine 之间的内存共享。

   **channel**（联想Unix管道）

   是go在语言级别提供的goroutine的通信方式，channel是进程内的通信方式，因此channel传递对象的方式和函数的传参方式基本是一致的，（可以传递指针等）

   如果需要跨进程通信，可以使用分布式系统的方法来解决，如使用HTTP/Socket，go对网络方面也有非常完善的支持

   并发程序的优点：

   - 客观表现问题模型
   - 充分利用CPU多核优势
   - 充分利用CPU与硬件固有的异步特性

3. goroutine创建

   - 通过普通函数创建
   - 通过匿名函数创建

   所有goroutine在main函数结束时才会一同结束

   Goroutine类似于线程概念，但是没有线程细致，细致程度取决于go程序的goroutine的调度器实现和运行环境

   终止 goroutine 的最好方法就是自然返回 goroutine 对应的函数。

4. 并发通信

   两种最常见的**并发通信模型：**共享数据和信息

   go提供另一种通信模型：即以消息机制而非共享内存作为通信方式

   **消息机制认为每个共享单元都是自包含的、独立的个体，他们有自己的变量，但在不同并发单元中这些变量不共享，每个单元的输入和输出只有一种，即是消息。类似于进程，不同进程间各自负责自己的任务就OK，不共享内存。**

   共享数据是指多个并发单元保持对同一个数据的引用，实现对该数据的共享，共享的数据可能有多种格式，如内存数据块、网络数据、磁盘文件等，最常用的是共享内存。

   并发编程难点在于协调调度，协调就要通过交流，因此从某种程度上来说，并发单元间的通信是最大的问题

5. 并发中的资源竞争

   有并发，就有资源竞争。比如同时对一个资源进行读写，这时候就会产生资源竞争（对于同一个资源的读写必须是原子化的，也就是说，同一时间只能允许有一个goroutine对共享资源进行读写操作。）

   `go build -race`运行生成的可执行文件，可以看到打印出的检测信息，可以检测共享资源竞争的问题

   go提供了传统的同步groutine机制，就是对共享资源加锁。

   `atomic 和 sync`原子函数和互斥锁

6. 调整运行时的并发性能

   `runtime.GOMAXPROCS(runtime.NumCPU())`

   Go 在GOMAXPROCS数量和任务数量相等时，可以做到并行执行，大多数情况下都是并发执行

7. goroutine和coroutine（Lua）的区别

   Coroutine运行机制属于协作式任务处理，需要程序主动交出CPU的使用权，而这在开发者未在程序完成时设置交出使用权的时候就容易出现死机或失去响应。

   goroutine属于抢占式任务处理，执行权交由操作系统，当某个任务处理时间过长，长时间占用大量CPU时，操作系统有权终止该任务。

8. **channel**（FIFO队列）

   go提倡用通信的方法代替共享内存，当一个资源需要在多个goroutine之间共享时，通道在goroutine之间架起一条管道，并确保数据能同步交换，声明通道（引用类型make）时，需要指定将要被共享的数据的类型。

   在任何时候，只能有一个goroutine访问通道进行发送和获取数据，goroutine间通过通道就可以通信。

   ```go
   ch := make(chan interface{})
   ch <- 0 // 发送0到接口通道
   ch <- "hello" // 发送字符串到接口通道
   data := <-ch // 执行到这里会阻塞，直到接收到数据并赋给data为止
   data, ok := <-ch // 非阻塞接收数据
   <- ch // 执行时发生阻塞，直到接收到数据，但会忽略接收的数据
   
   func main() {
     ch := make(chan int)
    // 开启一个匿名函数并发
     go func() {
       fmt.Println("start")
       ch <- 0
       fm.Println("end")
     }()
     fmt.Println("wait goroutine") // 匿名函数结束时通知另一个goroutine
     <- ch // 等待匿名goroutine
     fmt.Println("all done")
   }
   // wait goroutine
   // start
   // end
   // all done
   ```

   **使用通道接收数据**

   - 通道的收发操作需要在不同的两个goroutine中进行

     如果发送方一直发送，而没有接收方处理，会造成阻塞，因此通道的接收方需要在另一个goroutine中进行

   - 接收方将持续阻塞直到发送方发送数据

     如果接收数据时，发送方一直没有发送数据，接收方也会发生阻塞，直到发送方发送数据为止

   - 每次只接收一个数据

     阻塞接收数据

     非阻塞接收数据

     接收任意数据，但忽略接收的数据

     循环接收// 通道ch是可以进行遍历的

   **单向通道**

   通道本身是支持同时读写的，否则根本没法用

   声明方式：

   >var 通道实例 chan <- 元素类型 // 只能发送
   >
   >var 通道实例 <- chan 元素类型 // 只能接收

   ```go
   var ch = make(chan int)
   var sendOnly chan <- int = ch
   var receiveOnly <- chan int = ch
   // 在声明时即创建单向通道
   var ch1 = make(chan <- int)
   var readOnly chan <- int = ch1
   chan <-
   ```

   time包中的单向通道

   关闭通道：`close(ch)`

   `x, ok := <- ch`通过ok这个布尔值判断，为false则已关闭

   **无缓冲通道**

   要求收发双方都要准备好，才可以执行收发操作，因为其在接收前没有任何能力保存值。如果没有同时准备好，都可能发生阻塞。

   无缓冲的通道保证进行发送和接收的 goroutine 会在同一时间进行数据交换。

   模拟一个🎾网球比赛的场景，两个选手即是两个goroutine，而球是消息，选手要么在接球的状态，要么在发球的状态，球（消息）不可能说打到空中暂停了，即是说没有有缓冲。

   **带缓冲通道**

   在通道中没有要接收的值时，接收操作才会阻塞，通道中没有可缓冲区容纳被发送的值时，发送动作会阻塞（即，取不到值，和缓冲区满发不进去）

   `var 通道实例 := make(chan 通道类型, 缓冲大小)`

   无缓冲通道可以看作是缓冲大小永远为0的带缓冲通道

   为什么要设置缓冲大小？而不是无限制？

   因为当提供方的数据发送速度大于接收方的处理速度，通道不限制长度，会导致内存膨胀到应用崩溃。

   （供给量需要和消费方+缓冲大小之间做一个平衡）

   **通道的超时机制**

   go并没有提供直接的超时处理机制，所谓的超时可以理解为网站登录时间过长时会要求你重新登录

   这时可以使用select来处理超时

   select 的特点是只要其中有一个 case 已经完成，程序就会继续往下执行，而不会考虑其他 case 的情况

   ```go
   select {
     case <- chan1: 
     // 处理 ，每个case语句里必须有一个I/O操作，防止通道阻塞
     case chan2 <-1: 
     //
     default: // 保证了至少有一个可以进行下去
     //
   }
   ```

9. 多核并行化

   虽然goroutine简化了我们写并行代码的过程，但是实际运行效率可能并不真正高于单线程程序，你可以运行多个goroutine，从运行状态看也的确在并行运行，但是实际上这些goroutine都运行在一个CPU上。

10. 等待组（sync.WaitGroup)

    Go除了可以使用通道和互斥锁进行两个并发程序同步外，还可以使用等待组进行多个任务的同步

11. **死锁，活锁，饥饿锁**

    死锁是指两个或两个以上进程（或线程）在执行过程中，因为争夺资源而造成的一种相互等待的现象。若无外力作用，它们都将无法推动进行下去，这种一直卡着的相互等待的进程即为死锁进程。

    死锁发生的条件：

    - 互斥条件：一个线程占用了某个资源，其他的线程都处于等待状态，直到资源被释放
    - 请求和保持条件：T1占用了R1，还想占用R2，但是R2被T2占用了，于是T1继续等待，等待过程中还不放开R1
    - 不剥夺条件：说白了就是资源的使用权在自己手里，别人不能抢，只能用完后自己释放
    - 环路等待条件：T1在等待T2占用的资源，T2在等待T1占用的资源

    死锁解决办法：

    - 并发查询多个表时约定顺序
    - 同一个事务中，尽可能做到一次锁定需要获取的资源
    - 对容易产生死锁的业务场景，升级颗粒度，如使用表级锁
    - 使用分布式事务锁或者乐观锁

    活锁：即是指线程一直在重复同样的操作，如T1，T2，T3等线程都需要资源R1 ，但都让来让去，最后谁都没用上，通常发生在处理事务消息中，活锁可能自动解开，死锁却不能。

    饥饿：是指一个线程本可以继续执行，但是被调度器无限期的忽视而不能执行

    活锁与饥饿无关，活锁最终是没有完成任务的，而饥饿通常意味着一个或多个贪婪的进程，妨碍了其他线程或进程的继续执行。

    **总结：**

    - 死锁的原因是因为用锁不当
    - 活锁，是逻辑上感觉对，实际上可能在重复做某个操作
    - 与锁使用的粒度有关，通过计数取样，可以判断进程的工作效率

    只要是共享资源，都必定要使起其逻辑上进行顺序化和原子化，这避不开锁的使用。

12. 通信顺序进程

    并发编程中，对共享资源的精确控制访问，在绝大多数语言中，都是通过加锁等线程同步方案解决，而go是将共享值通过通道传递。

    go实现了两个并发形式，一种是类似java c++的多线程共享内存，一种是CSP（communicating sequential process)并发模型（未完全实现）（process -> grouting -> channel)

    **并发编程的核心概念是同步通信。**

***

**接口**

1. 

***

**文件处理**

1. 